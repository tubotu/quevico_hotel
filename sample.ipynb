{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ライブラリのインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_validate, cross_val_score, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score,auc,log_loss,roc_curve,roc_auc_score\n",
    "\n",
    "from xfeat import TargetEncoder\n",
    "import lightgbm as lgbm\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#notebookのプロットの設定\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('max_columns', 50)\n",
    "plt.style.use('bmh')\n",
    "color_pal = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "color_cycle = cycle(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習データのロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108785, 27) (10099, 26)\n"
     ]
    }
   ],
   "source": [
    "train_path = 'train.csv'\n",
    "test_path = 'test.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "df = pd.concat([train_df,test_df])\n",
    "print(train_df.shape,test_df.shape)\n",
    "\n",
    "df['arrival_date'] = pd.to_datetime(df['arrival_date'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数値変数と文字列(カテゴリ)変数をリストで保持しておく\n",
    "\n",
    "num_features = [\"lead_time\",\n",
    "                \"stays_in_weekend_nights\",\"stays_in_week_nights\",\"adults\",\"children\",\n",
    "                \"babies\",\"is_repeated_guest\", \"previous_cancellations\",\n",
    "                \"previous_bookings_not_canceled\",\"agent\",\"company\",\n",
    "                \"required_car_parking_spaces\", \"total_of_special_requests\", \"adr\"]\n",
    "\n",
    "cat_features = [\"hotel\",\"meal\",\"market_segment\",\n",
    "                \"distribution_channel\",\"reserved_room_type\",\"customer_type\"]\n",
    "\n",
    "features = num_features + cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#説明変数と目的変数を分ける。\n",
    "train_y = train_df[\"is_canceled\"]\n",
    "train_X = train_df.drop([\"is_canceled\",'arrival_date'], axis=1)[features]\n",
    "\n",
    "test_X = test_df.drop(['arrival_date'], axis=1)[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = KFold(n_splits=5, shuffle=True, random_state=71)\n",
    "cv = list(fold.split(train_X, train_y)) # もともとが generator なため明示的に list に変換する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_encoding_train(x_train, y_train,input_cols, fold):\n",
    "    train = pd.concat([x_train,y_train],axis=1)\n",
    "    encoder = TargetEncoder(\n",
    "        input_cols=input_cols,\n",
    "        target_col=y_train.name,\n",
    "        fold = fold,\n",
    "        output_suffix=\"_te\"\n",
    "    )\n",
    "    train = encoder.fit_transform(train)\n",
    "    return train.drop(['is_canceled']+input_cols,axis=1),train['is_canceled']\n",
    "\n",
    "def target_encoding_valid(x_train, y_train, x_valid, input_cols, fold):\n",
    "    for col in input_cols:\n",
    "        data_tmp = pd.DataFrame({col: x_train[col], 'target': y_train})\n",
    "        target_mean = data_tmp.groupby(col)['target'].mean()\n",
    "        x_valid.loc[:,col] = x_valid[col].map(target_mean)\n",
    "    return x_valid\n",
    "\n",
    "def target_encoding_cv(X, y,cat_features,fold, cv):\n",
    "    x_train_list = []\n",
    "    x_valid_list = []\n",
    "    y_train_list = []\n",
    "    y_valid_list = []\n",
    "    for (idx_train, idx_valid) in cv:\n",
    "        # training data を train/valid に分割\n",
    "        x_train, y_train = X.iloc[idx_train], y.iloc[idx_train]\n",
    "        x_valid, y_valid = X.iloc[idx_valid], y.iloc[idx_valid]\n",
    "        x_valid = target_encoding_valid(x_train, y_train, x_valid, cat_features, fold)\n",
    "        x_train, y_train = target_encoding_train(x_train, y_train, cat_features, fold)\n",
    "        x_train_list.append(x_train.values)\n",
    "        x_valid_list.append(x_valid.values)\n",
    "        y_train_list.append(y_train.values)\n",
    "        y_valid_list.append(y_valid.values)\n",
    "    return  x_train_list, x_valid_list, y_train_list, y_valid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_list, x_valid_list, y_train_list, y_valid_list = target_encoding_cv(train_X, train_y,cat_features,fold, cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習\n",
    "4foldのクロスバリデーションを行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lgbm(x_train_list, x_valid_list, y_train_list, y_valid_list, y, cv, params: dict=None, verbose=100):\n",
    "\n",
    "    # パラメータがないときはからの dict で置き換える\n",
    "    if params is None:\n",
    "        params = {}\n",
    "\n",
    "    models = []\n",
    "    oof_pred = np.zeros_like(y, dtype=np.float)\n",
    "\n",
    "    for x_train, x_valid, y_train, y_valid,(idx_train, idx_valid) in zip(x_train_list, x_valid_list, y_train_list, y_valid_list,cv):     \n",
    "        clf = lgbm.LGBMClassifier(**params)\n",
    "        clf.fit(x_train, y_train, \n",
    "                eval_set=[(x_valid, y_valid)],  \n",
    "                early_stopping_rounds=100, \n",
    "                #eval_metric=auc,\n",
    "                verbose=verbose)\n",
    "\n",
    "        pred_i = clf.predict_proba(x_valid)[:, 1]\n",
    "        oof_pred[idx_valid] = pred_i\n",
    "        models.append(clf)\n",
    "        \n",
    "    score =  roc_auc_score(y, oof_pred)\n",
    "    print('FINISHED \\ whole score: {:.4f}'.format(score))\n",
    "    return oof_pred, models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'learning_rate': 0.05,\n",
    "    'reg_lambda': 1.,\n",
    "    'n_estimators': 10000,\n",
    "    'metric': 'auc',\n",
    "    'colsample_bytree': .7,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.900391\n",
      "[200]\tvalid_0's auc: 0.907805\n",
      "[300]\tvalid_0's auc: 0.911917\n",
      "[400]\tvalid_0's auc: 0.914379\n",
      "[500]\tvalid_0's auc: 0.916587\n",
      "[600]\tvalid_0's auc: 0.918104\n",
      "[700]\tvalid_0's auc: 0.919066\n",
      "[800]\tvalid_0's auc: 0.920051\n",
      "[900]\tvalid_0's auc: 0.920917\n",
      "[1000]\tvalid_0's auc: 0.921628\n",
      "[1100]\tvalid_0's auc: 0.922309\n",
      "[1200]\tvalid_0's auc: 0.922803\n",
      "[1300]\tvalid_0's auc: 0.92317\n",
      "[1400]\tvalid_0's auc: 0.923485\n",
      "[1500]\tvalid_0's auc: 0.923813\n",
      "[1600]\tvalid_0's auc: 0.924319\n",
      "[1700]\tvalid_0's auc: 0.924782\n",
      "[1800]\tvalid_0's auc: 0.924933\n",
      "[1900]\tvalid_0's auc: 0.92521\n",
      "[2000]\tvalid_0's auc: 0.925342\n",
      "[2100]\tvalid_0's auc: 0.925619\n",
      "[2200]\tvalid_0's auc: 0.925817\n",
      "[2300]\tvalid_0's auc: 0.92593\n",
      "[2400]\tvalid_0's auc: 0.926028\n",
      "[2500]\tvalid_0's auc: 0.926178\n",
      "[2600]\tvalid_0's auc: 0.926356\n",
      "[2700]\tvalid_0's auc: 0.926543\n",
      "[2800]\tvalid_0's auc: 0.926669\n",
      "[2900]\tvalid_0's auc: 0.926738\n",
      "[3000]\tvalid_0's auc: 0.926759\n",
      "[3100]\tvalid_0's auc: 0.926849\n",
      "[3200]\tvalid_0's auc: 0.926881\n",
      "[3300]\tvalid_0's auc: 0.926848\n",
      "[3400]\tvalid_0's auc: 0.926979\n",
      "[3500]\tvalid_0's auc: 0.926982\n",
      "Early stopping, best iteration is:\n",
      "[3407]\tvalid_0's auc: 0.927\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.896391\n",
      "[200]\tvalid_0's auc: 0.903303\n",
      "[300]\tvalid_0's auc: 0.906867\n",
      "[400]\tvalid_0's auc: 0.90965\n",
      "[500]\tvalid_0's auc: 0.91153\n",
      "[600]\tvalid_0's auc: 0.912911\n",
      "[700]\tvalid_0's auc: 0.914317\n",
      "[800]\tvalid_0's auc: 0.915086\n",
      "[900]\tvalid_0's auc: 0.915784\n",
      "[1000]\tvalid_0's auc: 0.916415\n",
      "[1100]\tvalid_0's auc: 0.917094\n",
      "[1200]\tvalid_0's auc: 0.917662\n",
      "[1300]\tvalid_0's auc: 0.918037\n",
      "[1400]\tvalid_0's auc: 0.918623\n",
      "[1500]\tvalid_0's auc: 0.919089\n",
      "[1600]\tvalid_0's auc: 0.919383\n",
      "[1700]\tvalid_0's auc: 0.919731\n",
      "[1800]\tvalid_0's auc: 0.920027\n",
      "[1900]\tvalid_0's auc: 0.92034\n",
      "[2000]\tvalid_0's auc: 0.920581\n",
      "[2100]\tvalid_0's auc: 0.920845\n",
      "[2200]\tvalid_0's auc: 0.920941\n",
      "[2300]\tvalid_0's auc: 0.921054\n",
      "[2400]\tvalid_0's auc: 0.921227\n",
      "[2500]\tvalid_0's auc: 0.921323\n",
      "[2600]\tvalid_0's auc: 0.921458\n",
      "[2700]\tvalid_0's auc: 0.921504\n",
      "[2800]\tvalid_0's auc: 0.921662\n",
      "[2900]\tvalid_0's auc: 0.921789\n",
      "[3000]\tvalid_0's auc: 0.921806\n",
      "[3100]\tvalid_0's auc: 0.921805\n",
      "Early stopping, best iteration is:\n",
      "[3058]\tvalid_0's auc: 0.92186\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.897382\n",
      "[200]\tvalid_0's auc: 0.904499\n",
      "[300]\tvalid_0's auc: 0.908106\n",
      "[400]\tvalid_0's auc: 0.910623\n",
      "[500]\tvalid_0's auc: 0.912278\n",
      "[600]\tvalid_0's auc: 0.913945\n",
      "[700]\tvalid_0's auc: 0.915081\n",
      "[800]\tvalid_0's auc: 0.916338\n",
      "[900]\tvalid_0's auc: 0.917334\n",
      "[1000]\tvalid_0's auc: 0.918081\n",
      "[1100]\tvalid_0's auc: 0.91885\n",
      "[1200]\tvalid_0's auc: 0.919454\n",
      "[1300]\tvalid_0's auc: 0.91985\n",
      "[1400]\tvalid_0's auc: 0.920166\n",
      "[1500]\tvalid_0's auc: 0.920552\n",
      "[1600]\tvalid_0's auc: 0.920952\n",
      "[1700]\tvalid_0's auc: 0.921208\n",
      "[1800]\tvalid_0's auc: 0.921594\n",
      "[1900]\tvalid_0's auc: 0.921919\n",
      "[2000]\tvalid_0's auc: 0.922019\n",
      "[2100]\tvalid_0's auc: 0.922215\n",
      "[2200]\tvalid_0's auc: 0.922341\n",
      "[2300]\tvalid_0's auc: 0.922469\n",
      "[2400]\tvalid_0's auc: 0.92268\n",
      "[2500]\tvalid_0's auc: 0.922852\n",
      "[2600]\tvalid_0's auc: 0.922907\n",
      "[2700]\tvalid_0's auc: 0.923003\n",
      "[2800]\tvalid_0's auc: 0.923134\n",
      "[2900]\tvalid_0's auc: 0.923311\n",
      "[3000]\tvalid_0's auc: 0.923425\n",
      "[3100]\tvalid_0's auc: 0.923425\n",
      "Early stopping, best iteration is:\n",
      "[3018]\tvalid_0's auc: 0.923451\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.899234\n",
      "[200]\tvalid_0's auc: 0.906808\n",
      "[300]\tvalid_0's auc: 0.910703\n",
      "[400]\tvalid_0's auc: 0.913031\n",
      "[500]\tvalid_0's auc: 0.914788\n",
      "[600]\tvalid_0's auc: 0.916696\n",
      "[700]\tvalid_0's auc: 0.917933\n",
      "[800]\tvalid_0's auc: 0.918843\n",
      "[900]\tvalid_0's auc: 0.919721\n",
      "[1000]\tvalid_0's auc: 0.920411\n",
      "[1100]\tvalid_0's auc: 0.921121\n",
      "[1200]\tvalid_0's auc: 0.921544\n",
      "[1300]\tvalid_0's auc: 0.921854\n",
      "[1400]\tvalid_0's auc: 0.922207\n",
      "[1500]\tvalid_0's auc: 0.922431\n",
      "[1600]\tvalid_0's auc: 0.922877\n",
      "[1700]\tvalid_0's auc: 0.92313\n",
      "[1800]\tvalid_0's auc: 0.92331\n",
      "[1900]\tvalid_0's auc: 0.923467\n",
      "[2000]\tvalid_0's auc: 0.923737\n",
      "[2100]\tvalid_0's auc: 0.923953\n",
      "[2200]\tvalid_0's auc: 0.924078\n",
      "[2300]\tvalid_0's auc: 0.924236\n",
      "[2400]\tvalid_0's auc: 0.92425\n",
      "[2500]\tvalid_0's auc: 0.924453\n",
      "[2600]\tvalid_0's auc: 0.924657\n",
      "[2700]\tvalid_0's auc: 0.924754\n",
      "[2800]\tvalid_0's auc: 0.924818\n",
      "[2900]\tvalid_0's auc: 0.92494\n",
      "[3000]\tvalid_0's auc: 0.924986\n",
      "[3100]\tvalid_0's auc: 0.925034\n",
      "[3200]\tvalid_0's auc: 0.925108\n",
      "Early stopping, best iteration is:\n",
      "[3148]\tvalid_0's auc: 0.925148\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.897489\n",
      "[200]\tvalid_0's auc: 0.904817\n",
      "[300]\tvalid_0's auc: 0.908953\n",
      "[400]\tvalid_0's auc: 0.911417\n",
      "[500]\tvalid_0's auc: 0.913744\n",
      "[600]\tvalid_0's auc: 0.9153\n",
      "[700]\tvalid_0's auc: 0.916355\n",
      "[800]\tvalid_0's auc: 0.917395\n",
      "[900]\tvalid_0's auc: 0.918376\n",
      "[1000]\tvalid_0's auc: 0.919202\n",
      "[1100]\tvalid_0's auc: 0.919893\n",
      "[1200]\tvalid_0's auc: 0.920395\n",
      "[1300]\tvalid_0's auc: 0.920795\n",
      "[1400]\tvalid_0's auc: 0.921119\n",
      "[1500]\tvalid_0's auc: 0.921545\n",
      "[1600]\tvalid_0's auc: 0.921805\n",
      "[1700]\tvalid_0's auc: 0.922063\n",
      "[1800]\tvalid_0's auc: 0.922305\n",
      "[1900]\tvalid_0's auc: 0.92253\n",
      "[2000]\tvalid_0's auc: 0.922718\n",
      "[2100]\tvalid_0's auc: 0.922911\n",
      "[2200]\tvalid_0's auc: 0.923003\n",
      "[2300]\tvalid_0's auc: 0.923135\n",
      "[2400]\tvalid_0's auc: 0.923359\n",
      "[2500]\tvalid_0's auc: 0.923438\n",
      "[2600]\tvalid_0's auc: 0.9236\n",
      "[2700]\tvalid_0's auc: 0.923807\n",
      "[2800]\tvalid_0's auc: 0.92392\n",
      "[2900]\tvalid_0's auc: 0.923993\n",
      "[3000]\tvalid_0's auc: 0.924066\n",
      "[3100]\tvalid_0's auc: 0.92412\n",
      "[3200]\tvalid_0's auc: 0.92425\n",
      "[3300]\tvalid_0's auc: 0.924362\n",
      "[3400]\tvalid_0's auc: 0.924434\n",
      "[3500]\tvalid_0's auc: 0.924619\n",
      "[3600]\tvalid_0's auc: 0.924713\n",
      "[3700]\tvalid_0's auc: 0.924744\n",
      "[3800]\tvalid_0's auc: 0.924821\n",
      "[3900]\tvalid_0's auc: 0.924825\n",
      "[4000]\tvalid_0's auc: 0.924899\n",
      "[4100]\tvalid_0's auc: 0.925012\n",
      "[4200]\tvalid_0's auc: 0.92503\n",
      "[4300]\tvalid_0's auc: 0.925063\n",
      "[4400]\tvalid_0's auc: 0.925109\n",
      "[4500]\tvalid_0's auc: 0.925151\n",
      "[4600]\tvalid_0's auc: 0.92523\n",
      "[4700]\tvalid_0's auc: 0.925329\n",
      "Early stopping, best iteration is:\n",
      "[4676]\tvalid_0's auc: 0.92534\n",
      "FINISHED \\ whole score: 0.9245\n"
     ]
    }
   ],
   "source": [
    "oof, models = fit_lgbm(x_train_list, x_valid_list, y_train_list, y_valid_list, train_y, cv, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提出用csv出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_list = []\n",
    "for (idx_train, idx_valid) in cv:\n",
    "    # training data を train/valid に分割\n",
    "    x_train, y_train = train_X.iloc[idx_train], train_y.iloc[idx_train]\n",
    "    x_test = test_X.copy()\n",
    "    x_test_list.append(target_encoding_valid(x_train, y_train, x_test, cat_features, fold))\n",
    "    \n",
    "pred = np.array([model.predict_proba(x_test_list[i].values)[:, 1] for i,model in enumerate(models)])\n",
    "pred = np.mean(pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.44596374e-01 3.91636574e-01 1.68665258e-05 ... 4.32188330e-01\n",
      " 5.58882379e-01 4.44079328e-01]\n"
     ]
    }
   ],
   "source": [
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#予測値を提出用dataframeに格納\n",
    "submission = test_df.copy()\n",
    "submission['preds'] = pred\n",
    "submission[['id','preds']].to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
